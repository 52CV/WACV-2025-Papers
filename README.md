# WACV-2025-Papers
![Alt text](71b01f14605d807ad78d267e5528243.jpg)
## 会议时间：2025年2月28日–3月4日
## 会议网址：https://wacv2025.thecvf.com/
## ❣❣❣ WACV 2024 论文分类整理ing


## 查看2024年综述文献点这里↘️[2024-CV-Surveys](https://github.com/52CV/CV-Surveys)

## 2025 年论文分类汇总戳这里
↘️[WACV-2025-Papers](https://github.com/52CV/WACV-2025-Papers)
↘️[CVPR-2025-Papers](https://github.com/52CV/CVPR-2025-Papers)

## 2024 年论文分类汇总戳这里
↘️[WACV-2024-Papers](https://github.com/52CV/WACV-2024-Papers)
↘️[CVPR-2024-Papers](https://github.com/52CV/CVPR-2024-Papers)
↘️[ECCV-2024-Papers](https://github.com/52CV/ECCV-2024-Papers)


## [2023 年论文分类汇总戳这里](#0000)
## [2022 年论文分类汇总戳这里](#000)
## [2021 年论文分类汇总戳这里](#00)
## [2020 年论文分类汇总戳这里](#0)

## 2月11日更新共计 197+2 篇。
* [BioPose: Biomechanically-accurate 3D Pose Estimation from Monocular Videos](https://arxiv.org/abs/2501.07800)<br>:house:[project](https://m-usamasaleem.github.io/publication/BioPose/BioPose.html)
* [Breaking the Frame: Visual Place Recognition by Overlap Prediction](https://arxiv.org/abs/2406.16204)<br>:star:[code](https://github.com/weitong8591/vop)

<br>:star:[code]
<br>:house:[project]
ASDF

## Sound
* [NowYouSee Me: Context-Aware Automatic Audio Description](http://arxiv.org/abs/2412.10002v1)
* [SoundLoc3D: Invisible 3D Sound Source Localization and Classification Using a Multimodal RGB-D Acoustic Camera](http://arxiv.org/abs/2412.16861v1)

## Transformer
* [LowFormer: Hardware Efficient Design for Convolutional Transformer Backbones](https://arxiv.org/abs/2409.03460)

## Dense Prediction(密集预测)
* [Optimizing Dense Visual Predictions Through Multi-Task Coherence and Prioritization](http://arxiv.org/abs/2412.03179v1)<br>:star:[code](https://github.com/Klodivio355/MT-CP)

## Neural Radiance Fields
* [GANESH: Generalizable NeRF for Lensless Imaging](http://arxiv.org/abs/2411.04810v1)<br>:star:[code](https://rakesh-123-cryp.github.io/Rakesh.github.io/)

## Anomaly Detection(异常检测)
* [SPACE: SPAtial-aware Consistency rEgularization for anomaly detection in Industrial applications](http://arxiv.org/abs/2411.05822v1)
* [Adaptive Deviation Learning for Visual Anomaly Detection with Data Contamination](http://arxiv.org/abs/2411.09558v1)
* [Anomaly Detection for People with Visual Impairments Using an Egocentric 360-Degree Camera](http://arxiv.org/abs/2411.10945v1)
* [ROADS: Robust Prompt-driven Multi-Class Anomaly Detection under Domain Shift](http://arxiv.org/abs/2411.16049v1)
* [FUN-AD: Fully Unsupervised Learning for Anomaly Detection with Noisy Training Data](http://arxiv.org/abs/2411.16110v1)<br>:star:[code](https://github.com/HY-Vision-Lab/FUNAD)
* 异常定位
  * [Towards Zero-shot 3D Anomaly Localization](http://arxiv.org/abs/2412.04304v1)

## Deepfake 
* [DeCLIP: Decoding CLIP representations for deepfake localization](https://arxiv.org/abs/2409.08849)<br>:star:[code](https://github.com/bit-ml/DeCLIP)

## Robots(机器人)
* SLAM
  * [Uni-SLAM: Uncertainty-Aware Neural Implicit SLAM for Real-Time Dense Indoor Scene Reconstruction](http://arxiv.org/abs/2412.00242v1)<br>:star:[code](https://shaoxiang777.github.io/project/uni-slam/)
* 室内定位
  * [Multi-Surrogate-Teacher Assistance for Representation Alignment in Fingerprint-based Indoor Localization](http://arxiv.org/abs/2412.12189v1)

## Scene(场景)
* [LLaVA-SpaceSGG: Visual Instruct Tuning for Open-vocabulary Scene Graph Generation with Enhanced Spatial Relations](http://arxiv.org/abs/2412.06322v1)<br>:star:[code](https://github.com/Endlinc/LLaVA-SpaceSGG)

## Object Pose Estimation(物体姿态估计)
* [Generalizable Single-view Object Pose Estimation by Two-side Generating and Matching](http://arxiv.org/abs/2411.15860v1)<br>:star:[code](https://github.com/scy639/Gen2SM)

## Dataset/Benchmark(数据集/基准)
* [CT to PET Translation: A Large-scale Dataset and Domain-Knowledge-Guided Diffusion Approach](http://arxiv.org/abs/2410.21932v1)<br>:star:[code](https://github.com/thanhhff/CPDM)
* [PV-VTT: A Privacy-Centric Dataset for Mission-Specific Anomaly Detection and Natural Language Interpretation](http://arxiv.org/abs/2410.22623v1)
* [SynDroneVision: A Synthetic Dataset for Image-Based Drone Detection](http://arxiv.org/abs/2411.05633v1)
* [SEED4D: A Synthetic Ego--Exo Dynamic 4D Data Generator, Driving Dataset and Benchmark](http://arxiv.org/abs/2412.00730v1)<br>:star:[code](https://seed4d.github.io/)<br>:star:[code](https://github.com/continental/seed4d)
* [DrIFT: Autonomous Drone Dataset with Integrated Real and Synthetic Data, Flexible Views, and Transformed Domains](http://arxiv.org/abs/2412.04789v1)<br>:star:[code](https://github.com/CARG-uOttawa/DrIFT.git)
* [TimberVision: A Multi-Task Dataset and Framework for Log-Component Segmentation and Tracking in Autonomous Forestry Operations](http://arxiv.org/abs/2501.07360v1)<br>:star:[code](https://github.com/timbervision/timbervision)
* [A Pipeline and NIR-Enhanced Dataset for Parking Lot Segmentation](http://arxiv.org/abs/2412.13179v1)
* 基准
  * [GazeSearch: Radiology Findings Search Benchmark](http://arxiv.org/abs/2411.05780v1)
  * [ARTeFACT: Benchmarking Segmentation Models on Diverse Analogue Media Damage](http://arxiv.org/abs/2412.04580v1)<br>:star:[code](https://daniela997.github.io/ARTeFACT/)

## 虚拟头像
* [Gaussian Déjà-vu: Creating Controllable 3D Gaussian Head-Avatars with Enhanced Generalization and Personalization Abilities](https://arxiv.org/abs/2409.16147)

## Vision-Language
* [Active Learning for Vision-Language Models](http://arxiv.org/abs/2410.22187v1)
* [@Bench: Benchmarking Vision-Language Models for Human-centered Assistive Technology](https://arxiv.org/abs/2409.14215)<br>:star:[code](https://github.com/jystin/ATBench)<br>:house:[project](https://junweizheng93.github.io/publications/ATBench/ATBench.html)
* [Style-Pro: Style-Guided Prompt Learning for Generalizable Vision-Language Models](http://arxiv.org/abs/2411.16018v1)
* [Who Brings the Frisbee: Probing Hidden Hallucination Factors in Large Vision-Language Model via Causality Analysis](http://arxiv.org/abs/2412.02946v1)
* [Retaining and Enhancing Pre-trained Knowledge in Vision-Language Models with Prompt Ensembling](https://arxiv.org/abs/2412.07077)
* 视频语言
  * [ACE: Action Concept Enhancement of Video-Language Models in Procedural Videos](http://arxiv.org/abs/2411.15628v1)
* VLN
  * [To Ask or Not to Ask? Detecting Absence of Information in Vision and Language Navigation](http://arxiv.org/abs/2411.05831v1)
  * [Hijacking Vision-and-Language Navigation Agents with Adversarial Environmental Attacks](http://arxiv.org/abs/2412.02795v1)
* Visual Grounding
  * [Fine-Grained Spatial and Verbal Losses for 3D Visual Grounding](http://arxiv.org/abs/2411.03405v1)

## Semi/self-supervised learning(半/自监督)
* 自监督
  * [HEX: Hierarchical Emergence Exploitation in Self-Supervised Algorithms](http://arxiv.org/abs/2410.23200v1)
  * [Self-Supervised Learning with Probabilistic Density Labeling for Rainfall Probability Estimation](http://arxiv.org/abs/2412.05825v1)<br>:star:[code](https://github.com/joonha425/SSLPDL)

## MC/KD/Pruning(模型压缩/知识蒸馏/剪枝)
* KD 
  * [On Explaining Knowledge Distillation: Measuring and Visualising the Knowledge Transfer Process](http://arxiv.org/abs/2412.13943v1)

## Few/Zero-Shot Learning/DG/A(小/零样本/域泛化/域适应)
* 域适应
  * [Label Calibration in Source Free Domain Adaptation](http://arxiv.org/abs/2501.07072v1)
  * [AH-OCDA: Amplitude-based Curriculum Learning and Hopfield Segmentation Model for Open Compound Domain Adaptation](http://arxiv.org/abs/2412.02280v1)

## Deep Learning
* [Prior2Posterior: Model Prior Correction for Long-Tailed Learning](http://arxiv.org/abs/2412.16540v1)

# Machine Learning(机器学习)
* 类增量
  * [Covariance-based Space Regularization for Few-shot Class Incremental Learning](http://arxiv.org/abs/2411.01172v1)
  * [Strategic Base Representation Learning via Feature Augmentations for Few-Shot Class Incremental Learning](http://arxiv.org/abs/2501.09361v1)
* 对比学习
  * [MOOSS: Mask-Enhanced Temporal Contrastive Learning for Smooth State Evolution in Visual Reinforcement Learning](https://arxiv.org/abs/2409.02714)
* 持续学习
  * [Online-LoRA: Task-free Online Continual Learning via Low Rank Adaptation](http://arxiv.org/abs/2411.05663v1)<br>:star:[code](https://github.com/Christina200/Online-LoRA-official.git)
  * [Memory-efficient Continual Learning with Neural Collapse Contrastive](http://arxiv.org/abs/2412.02865v1)
  * [Exploring the Stability Gap in Continual Learning: The Role of the Classification Head](http://arxiv.org/abs/2411.04723v1)
* 多任务学习
  * [Diffusion-based Visual Anagram as Multi-task Learning](http://arxiv.org/abs/2412.02693v1)<br>:star:[code](https://github.com/Pixtella/Anagram-MTL)

## Motion Generation(人体运动生成)
* [SyncViolinist: Music-Oriented Violin Motion Generation Based on Bowing and Fingering](https://arxiv.org/abs/2412.08343)<br>:star:[code](https://github.com/Kakanat/SyncViolinist)

## GAN/Image Synthesis(图像生成)
* 纹理生成
  * [Make-A-Texture: Fast Shape-Aware Texture Generation in 3 Seconds](https://arxiv.org/abs/2412.07766)
* 图像生成
  * [RAW-Diffusion: RGB-Guided Diffusion Models for High-Fidelity RAW Image Generation](http://arxiv.org/abs/2411.13150v1)(https://github.com/SonyResearch/RAW-Diffusion)
  * [MegaFusion: Extend Diffusion Models towards Higher-resolution Image Generation without Further Tuning](https://arxiv.org/abs/2408.11001)<br>:star:[code](https://github.com/haoningwu3639/MegaFusion)<br>:house:[project](https://haoningwu3639.github.io/MegaFusion/)
* 食谱生成
  * [Retrieval Augmented Recipe Generation](http://arxiv.org/abs/2411.08715v1)
* 图像编辑
  * [Uniform Attention Maps: Boosting Image Fidelity in Reconstruction and Editing](http://arxiv.org/abs/2411.19652v1)<br>:star:[code](https://github.com/Mowenyii/Uniform-Attention-Maps)
  * [Diffusion-Based Conditional Image Editing through Optimized Inference with Guidance](http://arxiv.org/abs/2412.15798v1)
* 文本-图像
  * [DreamBlend: Advancing Personalized Fine-tuning of Text-to-Image Diffusion Models](http://arxiv.org/abs/2411.19390v1)
* 文本-3D 
  * [GANFusion: Feed-Forward Text-to-3D with Diffusion in GAN Space](http://arxiv.org/abs/2412.16717v1)<br>:star:[code](https://ganfusion.github.io/)
* 图像-图像翻译
  * [Uncertainty-Aware Regularization for Image-to-Image Translation](http://arxiv.org/abs/2412.01705v1)

## Visual Question Answering(视觉问答)
* [Foundation Models and Adaptive Feature Selection: A Synergistic Approach to Video Question Answering](https://arxiv.org/abs/2412.09230)
* [Perceive, Query & Reason: Enhancing Video QA with Question-Guided Temporal Queries](http://arxiv.org/abs/2412.19304v1)

## OCR
* [Text Change Detection in Multilingual Documents Using Image Comparison](http://arxiv.org/abs/2412.04137v1)

# 3D(三维重建\三维视觉)
* [Planar Gaussian Splatting](http://arxiv.org/abs/2412.01931v1)
* [LIPIDS: Learning-based Illumination Planning In Discretized (Light) Space for Photometric Stereo](https://arxiv.org/abs/2409.02716)
* [Instructive3D: Editing Large Reconstruction Models with Text Instructions](http://arxiv.org/abs/2501.04374v1)
* 深度估计
  * [GET-UP: GEomeTric-aware Depth Estimation with Radar Points UPsampling](https://arxiv.org/abs/2409.02720)
  * [Revisiting Disparity from Dual-Pixel Images: Physics-Informed Lightweight Depth Estimation](http://arxiv.org/abs/2411.04714v1)
  * [MonoPP: Metric-Scaled Self-Supervised Monocular Depth Estimation by Planar-Parallax Geometry in Automotive Applications](http://arxiv.org/abs/2411.19717v1)<br>:star:[code](https://mono-pp.github.io/)


## Point Cloud(点云)
* [PocoLoco: A Point Cloud Diffusion Model of Human Shape in Loose Clothing](http://arxiv.org/abs/2411.04249v1)<br>:star:[code](https://github.com/sidsunny/pocoloco)
* 3D 点云
  * [Test-Time Adaptation of 3D Point Clouds via Denoising Diffusion Models](http://arxiv.org/abs/2411.14495v1)<br>:star:[code](https://github.com/hamidreza-dastmalchi/3DD-TTA)
* 点云分类
  * [Point-GN: A Non-Parametric Network Using Gaussian Positional Encoding for Point Cloud Classification](http://arxiv.org/abs/2412.03056v1)
* 点云分割
  * [ZAHA: Introducing the Level of Facade Generalization and the Large-Scale Point Cloud Facade Semantic Segmentation Benchmark Dataset](http://arxiv.org/abs/2411.04865v1)
* 点云配准
  * [XR-MBT: Multi-modal Full Body Tracking for XR through Self-Supervision with Learned Depth Point Cloud Registration](https://arxiv.org/abs/2411.18377)

## Video
* 视频时许定位
  * [FlashVTG: Feature Layering and Adaptive Score Handling Network for Video Temporal Grounding](http://arxiv.org/abs/2412.13441v1)<br>:star:[code](https://github.com/Zhuo-Cao/FlashVTG)

## Person Re-id
* [ReMix: Training Generalized Person Re-identification on a Mixture of Data](http://arxiv.org/abs/2410.21938v1)
* [AnonyNoise: Anonymizing Event Data with Smart Noise to Outsmart Re-Identification and Preserve Privacy](http://arxiv.org/abs/2411.16440v1)<br>:star:[code](https://github.com/dfki-av/AnonyNoise)
* 换衣重识别
  * [DLCR: A Generative Data Expansion Framework via Diffusion for Clothes-Changing Person Re-ID](http://arxiv.org/abs/2411.07205v1)<br>:star:[code](https://github.com/CroitoruAlin/dlcr)
* 行人搜索
  * [Swap Path Network for Robust Person Search Pre-training](http://arxiv.org/abs/2412.05433v1)<br>:star:[code](https://github.com/LLNL/spnet)

## Action Detection(动作检测)
* 开放词汇动作检测
  * [Exploiting VLM Localizability and Semantics for Open Vocabulary Action Detection](http://arxiv.org/abs/2411.10922v1)<br>:star:[code](https://github.com/Cogito2012/OpenMixer)
* 基于骨架的动作识别
  * [Autoregressive Adaptive Hypergraph Transformer for Skeleton-based Activity Recognition](http://arxiv.org/abs/2411.05692v1)

## Human Pose Estimation
* 人体重建
  * [DiHuR: Diffusion-Guided Generalizable Human Reconstruction](http://arxiv.org/abs/2411.11903v1)
* 人体网格恢复
  * [Utilizing Uncertainty in 2D Pose Detectors for Probabilistic 3D Human Mesh Recovery](http://arxiv.org/abs/2411.16289v1)<br>:star:[code](https://github.com/twehrbein/humr)
* 三维姿态估计
  * [ReMP: Reusable Motion Prior for Multi-domain 3D Human Pose Estimation and Motion Inbetweening](http://arxiv.org/abs/2411.09435v1)<br>:star:[code](https://hojunjang17.github.io/ReMP)
* 人体运动恢复
  * [RopeTP: Global Human Motion Recovery via Integrating Robust Pose Estimation with Diffusion Trajectory Prior](https://arxiv.org/abs/2410.20358)
* 手势生成
  * [Conditional GAN for Enhancing Diffusion Models in Efficient and Authentic Global Gesture Generation from Audios](https://arxiv.org/abs/2410.20359)

## Medical Image Progress(医学影响处理)
* [PK-YOLO: Pretrained Knowledge Guided YOLO for Brain Tumor Detection in Multiplanar MRI Slices](http://arxiv.org/abs/2410.21822v1)<br>:star:[code](https://github.com/mkang315/PK-YOLO)
* [Volumetric Conditioning Module to Control Pretrained Diffusion Models for 3D Medical Images](http://arxiv.org/abs/2410.21826v1)<br>:star:[code](https://github.com/Ahn-Ssu/VCM)
* [AMNCutter: Affinity-Attention-Guided Multi-View Normalized Cutter for Unsupervised Surgical Instrument Segmentation](http://arxiv.org/abs/2411.03695v1)<br>:star:[code](https://github.com/MingyuShengSMY/AMNCutter)
* [SAM-DA: Decoder Adapter for Efficient Medical Domain Adaptation](http://arxiv.org/abs/2501.06836v1)
* [Multimodal Fusion Learning with Dual Attention for Medical Imaging](http://arxiv.org/abs/2412.01248v1)<br>:star:[code](https://github.com/misti1203/DRIFA-Net)
* [LQ-Adapter: ViT-Adapter with Learnable Queries for Gallbladder Cancer Detection from Ultrasound Image](http://arxiv.org/abs/2412.00374v1)<br>:star:[code](https://github.com/ChetanMadan/LQ-Adapter)
* 医学图像分割
  * [Generalizable Single-Source Cross-modality Medical Image Segmentation via Invariant Causal Mechanisms](http://arxiv.org/abs/2411.05223v1)<br>:star:[code](https://github.com/ratschlab/ICMSeg)
  * [MulModSeg: Enhancing Unpaired Multi-Modal Medical Image Segmentation with Modality-Conditioned Text Embedding and Alternating Training](http://arxiv.org/abs/2411.15576v1)<br>:star:[code](https://github.com/ChengyinLee/MulModSeg_2024)
  * [Uncertainty-Guided Cross Attention Ensemble Mean Teacher for Semi-supervised Medical Image Segmentation](http://arxiv.org/abs/2412.15380v1)<br>:star:[code](https://github.com/Meghnak13/UG-CEMT)
* 医学放射科报告生成
  * [ORID: Organ-Regional Information Driven Framework for Radiology Report Generation](http://arxiv.org/abs/2411.13025v1)
* MRI
  * [Continuous Spatio-Temporal Memory Networks for 4D Cardiac Cine MRI Segmentation](http://arxiv.org/abs/2410.23191v1)
  * [DiaMond: Dementia Diagnosis with Multi-Modal Vision Transformers Using MRI and PET](https://arxiv.org/abs/2410.23219)
  * [MRI Reconstruction with Regularized 3D Diffusion Model (R3DM)](http://arxiv.org/abs/2412.18723v1)

## Autonomous Driving(自动驾驶)
* [CoVLA: Comprehensive Vision-Language-Action Dataset for Autonomous Driving](https://arxiv.org/abs/2408.10845)<br>:house:[project](https://turingmotors.github.io/covla-ad/)
* [S3PT: Scene Semantics and Structure Guided Clustering to Boost Self-Supervised Pre-Training for Autonomous Driving](http://arxiv.org/abs/2410.23085v1)
* 轨迹预测
  * [Socially-Informed Reconstruction for Pedestrian Trajectory Forecasting](http://arxiv.org/abs/2412.04673v1)

## Biomedical(生物特征识别)
* 虹膜检测
  * [A Parametric Approach to Adversarial Augmentation for Cross-Domain Iris Presentation Attack Detection](https://arxiv.org/abs/2412.07199)

## UAV/Remote Sensing/Satellite Image(无人机/遥感/卫星图像)
* [PGRID: Power Grid Reconstruction in Informal Developments Using High-Resolution Aerial Imagery](http://arxiv.org/abs/2412.07944v1)
* [Pix2Poly: A Sequence Prediction Method for End-to-end Polygonal Building Footprint Extraction from Remote Sensing Imagery](http://arxiv.org/abs/2412.07899v1)<br>:star:[code](https://github.com/yeshwanth95/Pix2Poly)

## Object Tracking(目标跟踪)
* [MFTIQ: Multi-Flow Tracker with Independent Matching Quality Estimation](http://arxiv.org/abs/2411.09551v1)<br>:star:[code](https://github.com/serycjon/MFTIQ)
* [Improving Accuracy and Generalization for Efficient Visual Tracking](http://arxiv.org/abs/2411.18855v1)
* 点跟踪
  * [EgoPoints: Advancing Point Tracking for Egocentric Videos](http://arxiv.org/abs/2412.04592v1)<br>:star:[code](https://ahmaddarkhalil.github.io/EgoPoints/)

## Object Detection(目标检测)
* [Recurrence-based Vanishing Point Detection](http://arxiv.org/abs/2412.20666v1)
* [Mixed Patch Infrared-Visible Modality Agnostic Object Detection](https://arxiv.org/pdf/2404.18849v2)<br>:star:[code](https://github.com/heitorrapela/MiPa)<br>:house:[project](https://heitorrapela.github.io/MiPa/)
* [No Annotations for Object Detection in Art through Stable Diffusion](http://arxiv.org/abs/2412.06286v1)<br>:star:[code](https://github.com/patrick-john-ramos/nada)
* 3D OD  
  * [VADet: Multi-frame LiDAR 3D Object Detection using Variable Aggregation](http://arxiv.org/abs/2411.13186v1)
  * [V-MIND: Building Versatile Monocular Indoor 3D Detector with Diverse 2D Annotations](http://arxiv.org/abs/2412.11412v1)
* VOD 
  * [Beyond Boxes: Mask-Guided Spatio-Temporal Feature Aggregation for Video Object Detection](http://arxiv.org/abs/2412.04915v1)

## Super Resolution(超分辨率)
* [Boosting Diffusion Guidance via Learning Degradation-Aware Models for Blind Super Resolution](http://arxiv.org/abs/2501.08819v1)<br>:star:[code](https://github.com/ryanlu2240/Boosting-Diffusion-Guidance-via-Learning-Degradation-Aware-Models-for-Blind-Super-Resolution)

## Image/Video Retrieval(图像/视频检索)
* [SCOT: Self-Supervised Contrastive Pretraining For Zero-Shot Compositional Retrieval](http://arxiv.org/abs/2501.08347v1)
* [UCDR-Adapter: Exploring Adaptation of Pre-Trained Vision-Language Models for Universal Cross-Domain Retrieval](http://arxiv.org/abs/2412.10680v1)<br>:star:[code](https://github.com/fine68/UCDR2024)
* 图像检索
  * [Composed Image Retrieval for Training-Free Domain Conversion](http://arxiv.org/abs/2412.03297v1)<br>:star:[code](https://github.com/NikosEfth/freedom)
  * [FOR: Finetuning for Object Level Open Vocabulary Image Retrieval](http://arxiv.org/abs/2412.18806v1)
* 视频检索  
  * [ContextIQ: A Multimodal Expert-Based Video Retrieval System for Contextual Advertising](http://arxiv.org/abs/2410.22233v1)
* 信息检索
  * [Patchfinder: Leveraging Visual Language Models for Accurate Information Retrieval using Model Uncertainty](http://arxiv.org/abs/2412.02886v1)

## Image Captioning
* [Reframing Image Difference Captioning with BLIP2IDC and Synthetic Augmentation](http://arxiv.org/abs/2412.15939v1)

## Image/video Compression(图像/视频压缩)
* [All-in-One Image Compression and Restoration](https://arxiv.org/abs/2502.03649)
* [Efficient Progressive Image Compression with Variance-aware Masking](http://arxiv.org/abs/2411.10185v1)

## Image Classification(图像分类)
* [Enhancing Visual Classification using Comparative Descriptors](http://arxiv.org/abs/2411.05357v1)
* [Class-Conditioned Transformation for Enhanced Robust Image Classification](https://arxiv.org/abs/2303.15409)<br>:star:[code](https://github.com/tsachiblau/Class-Conditioned-Transformation-for-Enhanced-Robust-Image-Classification)

## Image Progress(图像/视频处理)
* 图像恢复
  * [Dropout the High-rate Downsampling: A Novel Design Paradigm for UHD Image Restoration](http://arxiv.org/abs/2411.06456v1)
* 图像修复
  * [SEM-Net: Efficient Pixel Modelling for image inpainting with Spatially Enhanced SSM](http://arxiv.org/abs/2411.06318v1)<br>:star:[code](https://github.com/ChrisChen1023/SEM-Net)
  * [I Dream My Painting: Connecting MLLMs and Diffusion Models via Prompt Generation for Text-Guided Multi-Mask Inpainting](http://arxiv.org/abs/2411.19050v1)<br>:star:[code](https://cilabuniba.github.io/i-dream-my-painting)
* 图像增强
  * [Deep Joint Unrolling for Deblurring and Low-Light Image Enhancement](https://arxiv.org/abs/2412.07527)
  * [VIIS: Visible and Infrared Information Synthesis for Severe Low-light Image Enhancement](http://arxiv.org/abs/2412.13655v1)<br>:star:[code](https://github.com/Chenz418/VIIS)
* 图像质量评估
  * [Dual-Representation Interaction Driven Image Quality Assessment with Restoration Assistance](https://arxiv.org/abs/2411.17390)<br>:star:[code](https://github.com/Jingtong0527/DRI-IQA)
* 视频修复
  * [VipDiff: Towards Coherent and Diverse Video Inpainting via Training-free Denoising Diffusion Models](http://arxiv.org/abs/2501.12267v1)
* 视频增强
  * [UnDIVE: Generalized Underwater Video Enhancement Using Generative Priors](http://arxiv.org/abs/2411.05886v1)
* 视频去模糊
  * [Adaptive High-Pass Kernel Prediction for Efficient Video Deblurring](http://arxiv.org/abs/2412.01559v1)<br>:star:[code](https://github.com/jibo27/AHFNet)

## Image Segmentation(图像分割)
* [HSDA: High-frequency Shuffle Data Augmentation for Bird's-Eye-View Map Segmentation](http://arxiv.org/abs/2412.06127v1)<br>:star:[code](https://github.com/Zarhult/HSDA)
* [Few-shot Structure-Informed Machinery Part Segmentation with Foundation Models and Graph Neural Networks](http://arxiv.org/abs/2501.10080v1)<br>:star:[code](https://github.com/AIT-Assistive-Autonomous-Systems/Hopomop)
* 实例分割
  * 3D实例分割
    * [Lifting by Gaussians: A Simple, Fast and Flexible Method for 3D Instance Segmentation](https://arxiv.org/abs/2502.00173)
* 语义分割
  * [COSNet: A Novel Semantic Segmentation Network using Enhanced Boundaries in Cluttered Scenes](http://arxiv.org/abs/2410.24139v1)
  * [Modality-Incremental Learning with Disjoint Relevance Mapping Networks for Image-based Semantic Segmentation](http://arxiv.org/abs/2411.17610v1)
  * [Epipolar Attention Field Transformers for Bird's Eye View Semantic Segmentation](http://arxiv.org/abs/2412.01595v1)
  * [Active Learning with Context Sampling and One-vs-Rest Entropy for Semantic Segmentation](http://arxiv.org/abs/2412.06470v1)
  * 半监督语义分割
    * [Uncertainty and Energy based Loss Guided Semi-Supervised Semantic Segmentation](http://arxiv.org/abs/2501.01640v1)
  * 小样本语义分割
    * [Generative Model-Based Fusion for Improved Few-Shot Semantic Segmentation of Infrared Images](http://arxiv.org/abs/2412.05341v1)
* VSS
  * [Event-guided Low-light Video Semantic Segmentation](http://arxiv.org/abs/2411.00639v1)
* VPS
  * [Balancing Shared and Task-Specific Representations: A Hybrid Approach to Depth-Aware Video Panoptic Segmentation](http://arxiv.org/abs/2412.07966v1)<br>:house:[project](https://research.khws.io/multiformer)

## Face
* [Continual Learning of Personalized Generative Face Models with Experience Replay](http://arxiv.org/abs/2412.02627v1)<br>:star:[code](https://anniedde.github.io/personalizedcontinuallearning.github.io/)
* 人脸识别
  * [PETALface: Parameter Efficient Transfer Learning for Low-resolution Face Recognition](https://arxiv.org/abs/2412.07771)<br>:house:[project](https://kartik-3004.github.io/PETALface/)
* 人脸验证
  * [Fairer Analysis and Demographically Balanced Face Generation for Fairer Face Verification](https://arxiv.org/abs/2412.03349)
* 人脸生成
  * [Analyzing and Improving the Skin Tone Consistency and Bias in Implicit 3D Relightable Face Generators](http://arxiv.org/abs/2411.12002v1)
* 人脸表情识别
  * [Facial Expression Recognition with Controlled Privacy Preservation and Feature Compensation](http://arxiv.org/abs/2412.00277v1)
* 人脸关键点检测
  * [Cascaded Dual Vision Transformer for Accurate Facial Landmark Detection](http://arxiv.org/abs/2411.07167v1)
  * [ORFormer: Occlusion-Robust Transformer for Accurate Facial Landmark Detection](http://arxiv.org/abs/2412.13174v1)

## Othere(其它)
* [Dense Depth from Event Focal Stack](http://arxiv.org/abs/2412.08120v1)
* [MAGMA: Manifold Regularization for MAEs](http://arxiv.org/abs/2412.02871v1)<br>:star:[code](https://github.com/adondera/magma)
* [Advancing Weight and Channel Sparsification with Enhanced Saliency](https://arxiv.org/abs/2502.03658)
* [SenCLIP: Enhancing zero-shot land-use mapping for Sentinel-2 with ground-level prompting](http://arxiv.org/abs/2412.08536v1)
* [Secrets of Edge-Informed Contrast Maximization for Event-Based Vision](https://arxiv.org/abs/2409.14611)
* [Multi-Class Textual-Inversion Secretly Yields a Semantic-Agnostic Classifier](http://arxiv.org/abs/2410.22317v1)<br>:star:[code](https://github.com/wangkai930418/mc_ti)
* [PACA: Perspective-Aware Cross-Attention Representation for Zero-Shot Scene Rearrangement](http://arxiv.org/abs/2410.22059v1)
* [Active Event Alignment for Monocular Distance Estimation](http://arxiv.org/abs/2410.22280v1)
* [Multi-Level Feature Distillation of Joint Teachers Trained on Distinct Image Datasets](http://arxiv.org/abs/2410.22184v1)<br>:star:[code](https://github.com/AdrianIordache/MLFD)
* [Self-Relaxed Joint Training: Sample Selection for Severity Estimation with Ordinal Noisy Labels](http://arxiv.org/abs/2410.21885v1)<br>:star:[code](https://github.com/shumpei-takezaki/Self-Relaxed-Joint-Training)
* [PTQ4VM: Post-Training Quantization for Visual Mamba](http://arxiv.org/abs/2412.20386v1)<br>:star:[code](https://github.com/YoungHyun197/ptq4vm)
* [Uncertainty-Aware Online Extrinsic Calibration: A Conformal Prediction Approach](http://arxiv.org/abs/2501.06878v1)
* [CorrFill: Enhancing Faithfulness in Reference-based Inpainting with Correspondence Guidance in Diffusion Models](http://arxiv.org/abs/2501.02355v1)<br>:star:[code](https://corrfill.github.io/)
* [CM3T: Framework for Efficient Multimodal Learning for Inhomogeneous Interaction Datasets](http://arxiv.org/abs/2501.03332v1)
* [RapidNet: Multi-Level Dilated Convolution Based Mobile Backbone](http://arxiv.org/abs/2412.10995v1)
* [Dataset Augmentation by Mixing Visual Concepts](http://arxiv.org/abs/2412.15358v1)
* [ACE: Anatomically Consistent Embeddings in Composition and Decomposition](http://arxiv.org/abs/2501.10131v1)
* [EI-Nexus: Towards Unmediated and Flexible Inter-Modality Local Feature Extraction and Matching for Event-Image Data](http://arxiv.org/abs/2410.21743v1)<br>:star:[code](https://github.com/ZhonghuaYi/EI-Nexus_official)
* [High-Fidelity Document Stain Removal via A Large-Scale Real-World Dataset and A Memory-Augmented Transformer](http://arxiv.org/abs/2410.22922v1)
* [SEMU-Net: A Segmentation-based Corrector for Fabrication Process Variations of Nanophotonics with Microscopic Images](http://arxiv.org/abs/2411.16973v1)
* [Situational Scene Graph for Structured Human-centric Situation Understanding](http://arxiv.org/abs/2410.22829v1)
* [Compositional Segmentation of Cardiac Images Leveraging Metadata](http://arxiv.org/abs/2410.23130v1)<br>:star:[code](https://github.com/kabbas570/CompSeg-MetaData)
* [DiffPAD: Denoising Diffusion-based Adversarial Patch Decontamination](http://arxiv.org/abs/2410.24006v1)
* [TPP-Gaze: Modelling Gaze Dynamics in Space and Time with Neural Temporal Point Processes](http://arxiv.org/abs/2410.23409v1)<br>:star:[code](https://github.com/phuselab/tppgaze)
* [MS-Glance: Non-semantic context vectors and the applications in supervising image reconstruction](http://arxiv.org/abs/2410.23577v1)<br>:star:[code](https://github.com/Z7Gao/MSGlance)
* [Debiasify: Self-Distillation for Unsupervised Bias Mitigation](http://arxiv.org/abs/2411.00711v1)
* [TaxaBind: A Unified Embedding Space for Ecological Applications](http://arxiv.org/abs/2411.00683v1)<br>:star:[code](https://github.com/mvrl/TaxaBind)
* [Towards High-fidelity Head Blending with Chroma Keying for Industrial Applications](http://arxiv.org/abs/2411.00652v1)<br>:star:[code](https://hahminlew.github.io/changer)
* [Through the Curved Cover: Synthesizing Cover Aberrated Scenes with Refractive Field](http://arxiv.org/abs/2411.06365v1)
* [HandCraft: Anatomically Correct Restoration of Malformed Hands in Diffusion Generated Images](http://arxiv.org/abs/2411.04332v1)
* [WAFFLE: Multimodal Floorplan Understanding in the Wild](https://arxiv.org/abs/2412.00955)<br>:house:[project](https://tau-vailab.github.io/WAFFLE/)
* [Distillation of Diffusion Features for Semantic Correspondence](http://arxiv.org/abs/2412.03512v1)<br>:star:[code](https://compvis.github.io/distilldift)
* [Divergent Domains, Convergent Grading: Enhancing Generalization in Diabetic Retinopathy Grading](http://arxiv.org/abs/2411.02614v1)<br>:star:[code](https://github.com/sharonchokuwa/dg-adr)
* [HeightMapNet: Explicit Height Modeling for End-to-End HD Map Learning](http://arxiv.org/abs/2411.01408v1)<br>:star:[code](https://github.com/adasfag/HeightMapNet/)
* [STLight: a Fully Convolutional Approach for Efficient Predictive Learning by Spatio-Temporal joint Processing](http://arxiv.org/abs/2411.10198v1)
* [Design-o-meter: Towards Evaluating and Refining Graphic Designs](http://arxiv.org/abs/2411.14959v1)<br>:star:[code](https://sahilg06.github.io/Design-o-meter/)
* [Ordinal Multiple-instance Learning for Ulcerative Colitis Severity Estimation with Selective Aggregated Transformer](http://arxiv.org/abs/2411.14750v1)<br>:star:[code](https://github.com/Shiku-Kaito/Ordinal-Multiple-instance-Learning-for-Ulcerative-Colitis-Severity-Estimation)
* [TreeFormer: Single-view Plant Skeleton Estimation via Tree-constrained Graph Generation](http://arxiv.org/abs/2411.16132v1)<br>:star:[code](https://github.com/huntorochi/TreeFormer/)
* [I Spy With My Little Eye: A Minimum Cost Multicut Investigation of Dataset Frames](http://arxiv.org/abs/2412.01296v1)<br>:star:[code](https://github.com/KathPra/MP4VisualFrameDetection)
* [Diffusion Model Guided Sampling with Pixel-Wise Aleatoric Uncertainty Estimation](http://arxiv.org/abs/2412.00205v1)
* [SimuScope: Realistic Endoscopic Synthetic Dataset Generation through Surgical Simulation and Diffusion Models](http://arxiv.org/abs/2412.02332v1)<br>:star:[code](https://github.com/SanoScience/SimuScope)
* [EgoSonics: Generating Synchronized Audio for Silent Egocentric Videos](http://arxiv.org/abs/2407.20592)<br>:house:[project](https://aashishrai3799.github.io/EgoSonics/)
* [Multi-view Image Diffusion via Coordinate Noise and Fourier Attention](http://arxiv.org/abs/2412.03756v1)
* [LLS: Local Learning Rule for Deep Neural Networks Inspired by Neural Activity Synchronization](https://arxiv.org/abs/2405.15868)
* [SHIP: Structural Hierarchies for Instance-dependent Partial Labels]<br>本文介绍了一个模块化组件，旨在无缝集成到深度学习架构中，特别是在标签层次结构存在的情况下。SHIP增强了基于实例的部分标签学习（PLL），并在各种算法中提高了2.6%的准确率！
* [Generating visual explanations from deep networks using implicit neural representations](http://arxiv.org/abs/2501.11784v1)


<a name="0"/>

## 2020 年论文分类汇总戳这里
↘️[CVPR-2020-Papers](https://github.com/52CV/CVPR-2020-Papers) 
↘️[ECCV-2020-Papers](https://github.com/52CV/ECCV-2020-Papers)

<a name="00"/>

## 2021 年论文分类汇总戳这里
↘️[ICCV-2021-Papers](https://github.com/52CV/ICCV-2021-Papers)
↘️[CVPR-2021-Papers](https://github.com/52CV/CVPR-2021-Papers)

<a name="000"/>

## 2022 年论文分类汇总戳这里
↘️[CVPR-2022-Papers](https://github.com/52CV/CVPR-2022-Papers/blob/main/README.md)
↘️[WACV-2022-Papers](https://github.com/52CV/WACV-2022-Papers)
↘️[ECCV-2022-Papers](https://github.com/52CV/ECCV-2022-Papers/blob/main/README.md)

<a name="0000"/>

## 2023 年论文分类汇总戳这里
↘️[CVPR-2023-Papers](https://github.com/52CV/CVPR-2023-Papers)
↘️[WACV-2023-Papers](https://github.com/52CV/WACV-2023-Papers)
↘️[ICCV-2023-Papers](https://github.com/52CV/ICCV-2023-Papers)
↘️[2023-CV-Surveys](https://github.com/52CV/CV-Surveys/blob/main/2023-CV-Surveys.md)

### 扫码CV君微信(注明：CVPR)入微信交流群：
![9475fa20fd5e95235d9fa23ae9587a2](https://user-images.githubusercontent.com/62801906/156720309-de92964f-a6da-464a-b21f-cfb270c13e27.png)